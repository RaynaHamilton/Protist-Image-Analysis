{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b149c4-90bf-4de2-8333-1288bf7f9c6e",
   "metadata": {},
   "source": [
    "# K-means & HLT Combined Approach\n",
    "This approach for cell identification and classification combines K-means clustering with Hough Line Transform (HLT). The workflow includes the following steps:\n",
    "1. read in RGB\n",
    "2. threshold cholor channels by percentile (with lower bounds)\n",
    "3. perform K-means clustering on thresholded image\n",
    "4. subset foreground to include ONLY red and blue clusters from threshold\n",
    "5. run edge detection on foreground to filter out large particles\n",
    "6. convert edges to binary/custom greyscale\n",
    "7. apply HLT\n",
    "8. count & report infected cells\n",
    "\n",
    "Other approaches have included Canny edge detection between steps 4 and 5 (or RH's blob removal function), and multuple line correction. Future directions will use Canny to filter the foreground mask by size (this will avoid plotting multiple lines over blobs). Some images with large particles (blobs) will overestimate the cell count, resulting in clustered cells.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f83ac19-7067-473f-96a5-3173f2c84098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import filters\n",
    "import skimage\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from math import sqrt\n",
    "\n",
    "# Set seed for K-means clustering reproducibility\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afeaa27-a0d9-4934-8712-ebae3acd197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION 1: threshold_image() will read image, split channels, threshold RB channels, return thresholded image\n",
    "    # input: image_path\n",
    "    # output: thresholded_image, thresh_combined_mask\n",
    "\n",
    "    # use foreground (-bg cluster) to start HLT\n",
    "        # convert to binary/customgreyscale\n",
    "        # run HLT\n",
    "\n",
    "\n",
    "# K-means approach as a function\n",
    "def threshold_image(image_path):\n",
    "    '''\n",
    "    This function will read in an image, split channels, threshold RB channels, \n",
    "    and return the original image, thresholded image, and threshold mask\n",
    "    inputs: image_path\n",
    "    outputs: image_rgb, thresholded_image, thresh_combined_mask\n",
    "    '''\n",
    "    # 1. Read image and convert to RGB\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Split into RGB channels for thresholding\n",
    "    red_channel = image_rgb[:, :, 0]\n",
    "    blue_channel = image_rgb[:, :, 2]\n",
    "    \n",
    "    # 2. Define thresholds for red and blue channels based on percentiles (OG R=90, B=92)\n",
    "    red_threshold = np.percentile(red_channel, 90)\n",
    "    blue_threshold = np.percentile(blue_channel, 92)\n",
    "        # Create binary masks for each color channel\n",
    "    _, red_mask = cv2.threshold(red_channel, red_threshold, 255, cv2.THRESH_BINARY)\n",
    "    _, blue_mask = cv2.threshold(blue_channel, blue_threshold, 255, cv2.THRESH_BINARY)\n",
    "        # Combine the red and blue masks\n",
    "    combined_mask = cv2.bitwise_or(red_mask, blue_mask)\n",
    "        # Apply the mask to isolate high-intensity pixels in the image\n",
    "    thresholded_image = cv2.bitwise_and(image_rgb, image_rgb, mask=combined_mask)\n",
    "        # VIBE IS GOOD ON THRESHOLD!\n",
    "        # Make mask from new threshold for K-means clustering\n",
    "    thresh_red_channel,thresh_blue_channel = thresholded_image[:, :, 0],thresholded_image[:, :, 2]\n",
    "    thresh_combined_mask = cv2.bitwise_or(thresh_red_channel, thresh_blue_channel)\n",
    "    #--------------\n",
    "    return image_rgb, thresholded_image, thresh_combined_mask\n",
    "\n",
    "\n",
    "\n",
    "# FUNCTION 2: cluster_foreground() takes a thresholded image and mask and returns an image with the background removed\n",
    "    # input: thresholded_image, thresh_combined_mask\n",
    "    # output: foreground_final\n",
    "\n",
    "def cluster_foreground(thresholded_image, thresh_combined_mask):\n",
    "    '''\n",
    "    This function takes a thresholded image and mask, performs K-means clustering, parses clusters by \n",
    "    RGB characteristics, and returns an image with the background removed.\n",
    "    input: thresholded_image, thresh_combined_mask\n",
    "    output: foreground_final\n",
    "    '''\n",
    "    # 3. Perform K-means clustering\n",
    "        # Flatten the masked pixels (ignore dark background)\n",
    "    masked_pixels = thresholded_image[thresh_combined_mask > 0]\n",
    "    pixels = masked_pixels.reshape((-1, 3)).astype(np.float32)\n",
    "        # Define K-means criteria and number of clusters\n",
    "    k = 4  # Number of clusters\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "        # Perform K-means clustering\n",
    "    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "        # Convert centers to uint8 for display\n",
    "    centers = np.uint8(centers)\n",
    "        # Reconstruct segmented data using labels\n",
    "    segmented_data = centers[labels.flatten()]\n",
    "        # Create an empty array to store the full-sized segmented image\n",
    "    segmented_image = np.zeros_like(thresholded_image)\n",
    "        # Fill in only the high-intensity pixels in the original mask\n",
    "    segmented_image[thresh_combined_mask > 0] = segmented_data\n",
    "\n",
    "    # 4. Subset mask by keeping only the clusters corresponding to red and blue\n",
    "        # Automate cluster characterization based on RBG values\n",
    "            # instantiate cluster values\n",
    "    bg_cluster,red_cluster,blue_cluster=-1,-1,-1\n",
    "        # instantiate list of color values outside loop\n",
    "    max_g_val,max_r_val,max_b_val = -1,-1,-1\n",
    "        # 4.1: Identify BACKGROUND cluster\n",
    "            # iterate over centers (RGB values)\n",
    "    for idx, cntr in enumerate(centers):\n",
    "            # set green value\n",
    "        g_val = cntr[1]\n",
    "            # compare to max green value\n",
    "        if g_val > max_g_val:\n",
    "                # update max green value\n",
    "            max_g_val = g_val\n",
    "                # set max green value to background cluster\n",
    "            bg_cluster = idx\n",
    "        # 4.2: Identify RED cluster\n",
    "    for idx, cntr in enumerate(centers):\n",
    "            # exclude cluster previously identified as bg\n",
    "        if idx != bg_cluster:\n",
    "            # set red value\n",
    "            r_val = cntr[0]\n",
    "            # compare to max red value\n",
    "            if r_val > max_r_val:\n",
    "                max_r_val = r_val\n",
    "                red_cluster = idx\n",
    "        # 4.3: Identify BLUE cluster\n",
    "    for idx, cntr in enumerate(centers):\n",
    "            # exclude clusters previously identified as bg & red\n",
    "        if idx != bg_cluster and idx != red_cluster:\n",
    "            # set red value\n",
    "            b_val = cntr[2]\n",
    "            # compare to max red value\n",
    "            if b_val > max_b_val:\n",
    "                max_b_val = b_val\n",
    "                blue_cluster = idx\n",
    "    print(centers)\n",
    "    print(\"Background cluster is\", bg_cluster)\n",
    "    print(\"Red cluster is\", red_cluster)\n",
    "    print(\"Blue cluster is\", blue_cluster)\n",
    "        # Reshape labels to match combined_mask shape\n",
    "            # CHANGE combined_mask with thresh_combined_mask--YES?\n",
    "    labels_reshaped = np.zeros(thresh_combined_mask.shape, dtype=int)\n",
    "        # CHANGE TO INCLUDE thresholded_image INSTEAD OF combined_mask\n",
    "    labels_reshaped[thresh_combined_mask > 0] = labels.flatten()\n",
    "        # Create a mask that includes only the red and blue clusters\n",
    "    foreground_mask = np.isin(labels_reshaped, [red_cluster, blue_cluster])\n",
    "    # foreground_mask = np.isin(labels_reshaped, -bg_cluster)\n",
    "        # Initialize the foreground image with black background\n",
    "            # CHANGE to thresholded_image (where bg is actually black)--YES\n",
    "    # foreground_final = np.zeros_like(image_rgb)\n",
    "    foreground_final = np.zeros_like(thresholded_image)\n",
    "        # Apply the mask to keep only the red and blue clusters\n",
    "    foreground_final[foreground_mask] = image_rgb[foreground_mask]\n",
    "    #--------------\n",
    "    return foreground_final\n",
    "\n",
    "def remove_large_background(array,window_size=30,step_size=10,max_mean=250):\n",
    "    '''\n",
    "    Scans across an image and removes large pixel blobs i.e. blocks where almost all pixels are filled in.\n",
    "    Parameters:\n",
    "    array: input 2d array of pixels (e.g. color channel)\n",
    "    window_size: size of box used when calculating proportion of filled pixels.  Should be larger than desired cell width.\n",
    "    step_size: movement distance between one window and the next\n",
    "    max_mean: mean that pixels in a window must reach for them to be removed.\n",
    "    '''\n",
    "    clean_array=np.copy(array)\n",
    "    for i in range(0,len(array)-window_size,step_size):\n",
    "        for j in range(0,len(array[i])-window_size,step_size):    \n",
    "            subset=array[i:i+window_size,j:j+window_size]\n",
    "            if subset.mean()>max_mean:\n",
    "                clean_array[max(i-step_size,0):min(i+window_size+step_size,len(array)-1),max(j-window_size,0):min(j+window_size+step_size,len(array[i]))]=0 #replace pixels of region passing max_mean threshold with 0\n",
    "    return clean_array\n",
    "\n",
    "# FUNCTION 3: reads in foreground image, extract channels, converts to custom greyscale for HLT\n",
    "    # input: foreground_final\n",
    "    # output: custom_gray\n",
    "def make_custom_grayscale(foreground_final):\n",
    "    '''\n",
    "    Read in an image (subsetted to remove background), convert red and blue channels\n",
    "    to a single grayscale array by taking the max at each coordinate. Resize image from \n",
    "    original dimensions (1388x1040) to new dimensions (160x120). Return gray image and resized image.\n",
    "    input: foreground_final\n",
    "    output: custom_gray, img\n",
    "    '''    \n",
    "    fore_red_channel,fore_blue_channel=foreground_final[:, :, 0],foreground_final[:, :, 2]\n",
    "    custom_gray=[]\n",
    "    # 5. Convert to custom greyscale for HLT\n",
    "        # MAY dampen intensity too much..?\n",
    "    for i,row in enumerate(fore_red_channel):\n",
    "        custom_gray.append([])\n",
    "        for j,col in enumerate(row):\n",
    "            if fore_red_channel[i,j]>fore_blue_channel[i,j]:\n",
    "                custom_gray[-1].append(fore_red_channel[i,j]*255)\n",
    "            else:\n",
    "                custom_gray[-1].append(fore_blue_channel[i,j]*255)\n",
    "    custom_gray=np.array(custom_gray).astype(np.uint8)\n",
    "    # make smaller image copies for hough line detection\n",
    "    backup=np.copy(foreground_final)\n",
    "    image=cv2.resize(backup,(160,120))\n",
    "    img = np.copy(cv2.resize(custom_gray,(160,120)))\n",
    "    img=img*255\n",
    "    # CHANGED\n",
    "    # edges = cv2.resize(custom_gray,(160,120))\n",
    "    return custom_gray, img\n",
    "\n",
    "def remove_overlapping_lines(lines,slope_threshold=0.2,distance_threshold=4):\n",
    "    '''\n",
    "    Removes very similar/redundant lines produced by hough line transformation.\n",
    "    For an array of line coordinates, finds pairs of lines with start or end points within distance_threshold of each otehr and slopes within slope_threshold of each other, then removes the shorter line.\n",
    "    '''\n",
    "    line_slopes=[]\n",
    "    for line in lines:\n",
    "        # subtract inital x/y from second x/y and divide to get slope\n",
    "            # IS THIS WHERE IT'S ADJUSTING THE SLOPE?\n",
    "                # ALSO NEED TO SET A LENGTH LIMIT\n",
    "        line_slopes.append((line[3]-line[1])/(line[2]-line[0])) \n",
    "    \n",
    "    indices_to_remove=[]\n",
    "    for i,slope1 in enumerate(line_slopes):\n",
    "        for j,slope2 in enumerate(line_slopes):\n",
    "            if i<j:\n",
    "                # WHAT IS THE VALUE/MEANING OF A SLOPE THRESHOLD?\n",
    "                if abs(slope2-slope1)<=slope_threshold: #examine pairs of lines with slopes within slope threshold\n",
    "                    line1,line2=lines[i],lines[j]\n",
    "                    x11,y11,x12,y12=line1 #first x coordinate, first y coordinate, second x coordinate, second y coordinate of line 1\n",
    "                    x21,y21,x22,y22=line2 #first x coordinate, first y coordinate, second x coordinate, second y coordinate of line 2\n",
    "                    #if (abs(x11-x21)<=distance_threshold and abs(y11-y21)<=distance_threshold) or (abs(x11-x22)<=distance_threshold and abs(y11-y22)<=distance_threshold) or (abs(x12-x21)<=distance_threshold and abs(y12-y21)<=distance_threshold) or (abs(x12-x22)<=distance_threshold and abs(y12-y22)<=distance_threshold):\n",
    "                    if (sqrt((x11-x21)**2+(y11-y21)**2)<=distance_threshold) or (sqrt((x11-x22)**2+(y11-y22)**2)<=distance_threshold) or (sqrt((x12-x21)**2+(y12-y21)**2)<=distance_threshold) or (sqrt((x12-x22)**2+(y12-y22)**2)<=distance_threshold):\n",
    "                        #Keep longer line:\n",
    "                            # I'M SUSPICIOUS OF THIS ASSUMPTION\n",
    "                        if sqrt((x11-x12)**2 + (y11-y12)**2) > sqrt((x21-x22)**2 + (y21-y22)**2):\n",
    "                            indices_to_remove.append(j)\n",
    "                        else:\n",
    "                            indices_to_remove.append(i)\n",
    "    new_lines=[]\n",
    "    #image=cv2.resize(backup,(x_size, y_size))\n",
    "    for i,line in enumerate(lines):\n",
    "        if i not in indices_to_remove:\n",
    "            x1,y1,x2,y2=line\n",
    "            new_lines.append(line)\n",
    "            #cv2.line(image,(x1,y1),(x2,y2),(np.random.randint(50,255),np.random.randint(50,255),np.random.randint(50,255)),2)\n",
    "    #plt.imshow(image)\n",
    "    print(f\"Removed {len(set(indices_to_remove))} very similar lines.\")\n",
    "    return new_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b61b1b-4d40-4587-a9ed-3e9a08bf8cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing GoodEarlySilica_AS_A_I_15_6_20240717.jpg\n",
      "[[ 48   0 130]\n",
      " [ 55   0 221]\n",
      " [231 222 234]\n",
      " [ 82   0  68]]\n",
      "Background cluster is 2\n",
      "Red cluster is 3\n",
      "Blue cluster is 1\n",
      "I counted 25 cells.\n",
      "Infection proportions are being calculated...\n",
      "Image processing complete.\n",
      "\n",
      "Individual Cell Blue:Red Ratios\n",
      "    Cell Number  Red Intensity Sum  Blue Intensity Sum  Blue:Red Ratio  \\\n",
      "0             0             366898              305727        0.833275   \n",
      "1             1             652351              518123        0.794240   \n",
      "2             2             435194              412439        0.947713   \n",
      "3             3             546848              366830        0.670808   \n",
      "4             4             428239              318375        0.743452   \n",
      "5             5             513491              338209        0.658646   \n",
      "6             6             391668              393695        1.005175   \n",
      "7             7             420980              274375        0.651753   \n",
      "8             8             363039              504501        1.389661   \n",
      "9             9             472954              348774        0.737437   \n",
      "10           10             329960              221271        0.670599   \n",
      "11           11             365608              355280        0.971751   \n",
      "12           12             196721              272760        1.386532   \n",
      "13           13             660387              531299        0.804527   \n",
      "14           14             411572              311345        0.756478   \n",
      "15           15             213757              189686        0.887391   \n",
      "16           16             245584              357521        1.455799   \n",
      "17           17             137497              105224        0.765282   \n",
      "18           18             159891              133988        0.837996   \n",
      "19           19             322045              244879        0.760388   \n",
      "20           20             313538              264000        0.842003   \n",
      "21           21             316325              387196        1.224045   \n",
      "22           22             238159              215107        0.903208   \n",
      "23           23             295313              192463        0.651725   \n",
      "24           24             447411              333187        0.744700   \n",
      "\n",
      "    Proportion Infected  \n",
      "0              0.454528  \n",
      "1              0.442661  \n",
      "2              0.486577  \n",
      "3              0.401487  \n",
      "4              0.426425  \n",
      "5              0.397099  \n",
      "6              0.501290  \n",
      "7              0.394583  \n",
      "8              0.581531  \n",
      "9              0.424440  \n",
      "10             0.401412  \n",
      "11             0.492837  \n",
      "12             0.580982  \n",
      "13             0.445838  \n",
      "14             0.430679  \n",
      "15             0.470168  \n",
      "16             0.592801  \n",
      "17             0.433518  \n",
      "18             0.455929  \n",
      "19             0.431943  \n",
      "20             0.457113  \n",
      "21             0.550369  \n",
      "22             0.474571  \n",
      "23             0.394573  \n",
      "24             0.426836  \n",
      "\n",
      "Total Cells: 25\n",
      "Overall Blue:Red Ratio in Image: 1.71\n",
      "Saved results to ../figures/Combined_classification/subset/data/GoodEarlySilica_AS_A_I_15_6_20240717.csv\n",
      "Saved labeled image to ../figures/Combined_classification/subset/classified/GoodEarlySilica_AS_A_I_15_6_20240717_labeled.jpg\n",
      "\n",
      "Processing GoodLate_THN_A_I_15_2_20240726.jpg\n",
      "[[242 237 246]\n",
      " [137   2  64]\n",
      " [ 41   0  70]\n",
      " [ 35   0 189]]\n",
      "Background cluster is 0\n",
      "Red cluster is 1\n",
      "Blue cluster is 3\n",
      "I counted 11 cells.\n",
      "Infection proportions are being calculated...\n",
      "Image processing complete.\n",
      "\n",
      "Individual Cell Blue:Red Ratios\n",
      "    Cell Number  Red Intensity Sum  Blue Intensity Sum  Blue:Red Ratio  \\\n",
      "0             0             221132              520957        2.355864   \n",
      "1             1             506150              211641        0.418139   \n",
      "2             2             643663              218681        0.339745   \n",
      "3             3             413489              205813        0.497747   \n",
      "4             4             376576              821580        2.181711   \n",
      "5             5             522691              221868        0.424473   \n",
      "6             6             136016              418841        3.079351   \n",
      "7             7             248725              539929        2.170787   \n",
      "8             8             436561              158891        0.363961   \n",
      "9             9             419212              149733        0.357177   \n",
      "10           10             233308              118218        0.506704   \n",
      "\n",
      "    Proportion Infected  \n",
      "0              0.702014  \n",
      "1              0.294850  \n",
      "2              0.253589  \n",
      "3              0.332331  \n",
      "4              0.685704  \n",
      "5              0.297986  \n",
      "6              0.754863  \n",
      "7              0.684621  \n",
      "8              0.266841  \n",
      "9              0.263177  \n",
      "10             0.336299  \n",
      "\n",
      "Total Cells: 11\n",
      "Overall Blue:Red Ratio in Image: 2.14\n",
      "Saved results to ../figures/Combined_classification/subset/data/GoodLate_THN_A_I_15_2_20240726.csv\n",
      "Saved labeled image to ../figures/Combined_classification/subset/classified/GoodLate_THN_A_I_15_2_20240726_labeled.jpg\n",
      "\n",
      "Processing ClumpyLate_AS_C_I_22_2_20240724.jpg\n",
      "[[ 39   1 100]\n",
      " [241 236 240]\n",
      " [ 58   0  45]\n",
      " [ 40   0 214]]\n",
      "Background cluster is 1\n",
      "Red cluster is 2\n",
      "Blue cluster is 3\n",
      "I counted 45 cells.\n",
      "Infection proportions are being calculated...\n",
      "Image processing complete.\n",
      "\n",
      "Individual Cell Blue:Red Ratios\n",
      "    Cell Number  Red Intensity Sum  Blue Intensity Sum  Blue:Red Ratio  \\\n",
      "0             0             208986              224761        1.075484   \n",
      "1             1             211817              218170        1.029993   \n",
      "2             2             368590              255301        0.692642   \n",
      "3             3             202910              227570        1.121532   \n",
      "4             4             412306              242843        0.588987   \n",
      "5             5             375694              170771        0.454548   \n",
      "6             6             120976               62908        0.520004   \n",
      "7             7             442123              279389        0.631926   \n",
      "8             8             206568              146402        0.708735   \n",
      "9             9             216371              116856        0.540072   \n",
      "10           10             337531              349089        1.034243   \n",
      "11           11             109616              165487        1.509697   \n",
      "12           12             339529              244662        0.720592   \n",
      "13           13             141512               91722        0.648157   \n",
      "14           14             197663              159492        0.806888   \n",
      "15           15             239019              110179        0.460963   \n",
      "16           16             265200              201104        0.758311   \n",
      "17           17             118685              343529        2.894460   \n",
      "18           18             307038              621546        2.024329   \n",
      "19           19             168922              309435        1.831822   \n",
      "20           20             320274              141069        0.440463   \n",
      "21           21             223517              239876        1.073189   \n",
      "22           22             218440             1009432        4.621095   \n",
      "23           23             172928              207136        1.197816   \n",
      "24           24             247888              222173        0.896264   \n",
      "25           25             181169              249832        1.379000   \n",
      "26           26             137421              221212        1.609739   \n",
      "27           27             350793              259823        0.740673   \n",
      "28           28             180937              826469        4.567717   \n",
      "29           29             123791              168644        1.362328   \n",
      "30           30             157452               73448        0.466479   \n",
      "31           31             186999              274829        1.469682   \n",
      "32           32              52084              401440        7.707549   \n",
      "33           33             207183              581037        2.804463   \n",
      "34           34             282558              286358        1.013449   \n",
      "35           35             296089              269299        0.909520   \n",
      "36           36             170552              250796        1.470496   \n",
      "37           37             154123              156738        1.016967   \n",
      "38           38              75828              383867        5.062338   \n",
      "39           39             170598              133864        0.784675   \n",
      "40           40             160217              735350        4.589713   \n",
      "41           41              57476              431571        7.508717   \n",
      "42           42             327523              205332        0.626924   \n",
      "43           43             162160              154312        0.951603   \n",
      "44           44              86117              439682        5.105635   \n",
      "\n",
      "    Proportion Infected  \n",
      "0              0.518185  \n",
      "1              0.507387  \n",
      "2              0.409208  \n",
      "3              0.528642  \n",
      "4              0.370668  \n",
      "5              0.312501  \n",
      "6              0.342107  \n",
      "7              0.387227  \n",
      "8              0.414772  \n",
      "9              0.350680  \n",
      "10             0.508417  \n",
      "11             0.601546  \n",
      "12             0.418805  \n",
      "13             0.393262  \n",
      "14             0.446562  \n",
      "15             0.315520  \n",
      "16             0.431272  \n",
      "17             0.743225  \n",
      "18             0.669348  \n",
      "19             0.646870  \n",
      "20             0.305779  \n",
      "21             0.517651  \n",
      "22             0.822099  \n",
      "23             0.545003  \n",
      "24             0.472647  \n",
      "25             0.579655  \n",
      "26             0.616820  \n",
      "27             0.425510  \n",
      "28             0.820393  \n",
      "29             0.576689  \n",
      "30             0.318094  \n",
      "31             0.595090  \n",
      "32             0.885157  \n",
      "33             0.737151  \n",
      "34             0.503340  \n",
      "35             0.476308  \n",
      "36             0.595223  \n",
      "37             0.504206  \n",
      "38             0.835047  \n",
      "39             0.439674  \n",
      "40             0.821100  \n",
      "41             0.882473  \n",
      "42             0.385343  \n",
      "43             0.487601  \n",
      "44             0.836217  \n",
      "\n",
      "Total Cells: 45\n",
      "Overall Blue:Red Ratio in Image: 1.52\n",
      "Saved results to ../figures/Combined_classification/subset/data/ClumpyLate_AS_C_I_22_2_20240724.csv\n",
      "Saved labeled image to ../figures/Combined_classification/subset/classified/ClumpyLate_AS_C_I_22_2_20240724_labeled.jpg\n",
      "\n",
      "Processing ClumpyLate_THN_A_I_15_5_20240726.jpg\n",
      "[[241 235 245]\n",
      " [ 50   0  91]\n",
      " [ 57   0 210]\n",
      " [142   4  95]]\n",
      "Background cluster is 0\n",
      "Red cluster is 3\n",
      "Blue cluster is 2\n",
      "I counted 15 cells.\n",
      "Infection proportions are being calculated...\n",
      "Image processing complete.\n",
      "\n",
      "Individual Cell Blue:Red Ratios\n",
      "    Cell Number  Red Intensity Sum  Blue Intensity Sum  Blue:Red Ratio  \\\n",
      "0             0             384083             1033133        2.689869   \n",
      "1             1             273098              492721        1.804191   \n",
      "2             2             255101              777590        3.048165   \n",
      "3             3             428902             1251315        2.917485   \n",
      "4             4             105452              338382        3.208872   \n",
      "5             5             390823              307970        0.788004   \n",
      "6             6             127166              517839        4.072150   \n",
      "7             7             373069              552185        1.480115   \n",
      "8             8             469132              219759        0.468437   \n",
      "9             9             220491              621880        2.820433   \n",
      "10           10              43681              214022        4.899659   \n",
      "11           11              53882              329739        6.119650   \n",
      "12           12             182279              682448        3.743975   \n",
      "13           13             119091              276465        2.321460   \n",
      "14           14              39272              143415        3.651838   \n",
      "\n",
      "    Proportion Infected  \n",
      "0              0.728988  \n",
      "1              0.643391  \n",
      "2              0.752975  \n",
      "3              0.744734  \n",
      "4              0.762407  \n",
      "5              0.440717  \n",
      "6              0.802845  \n",
      "7              0.596793  \n",
      "8              0.319004  \n",
      "9              0.738250  \n",
      "10             0.830499  \n",
      "11             0.859544  \n",
      "12             0.789206  \n",
      "13             0.698928  \n",
      "14             0.785031  \n",
      "\n",
      "Total Cells: 15\n",
      "Overall Blue:Red Ratio in Image: 1.95\n",
      "Saved results to ../figures/Combined_classification/subset/data/ClumpyLate_THN_A_I_15_5_20240726.csv\n",
      "Saved labeled image to ../figures/Combined_classification/subset/classified/ClumpyLate_THN_A_I_15_5_20240726_labeled.jpg\n",
      "\n",
      "Processing EasyEarly_AS_A_U_22_5_20240717.jpg\n",
      "[[ 41   0 235]\n",
      " [230 220 243]\n",
      " [ 42   0 148]\n",
      " [ 66   0  74]]\n",
      "Background cluster is 1\n",
      "Red cluster is 3\n",
      "Blue cluster is 0\n",
      "I counted 159 cells.\n",
      "Infection proportions are being calculated...\n",
      "Image processing complete.\n",
      "\n",
      "Individual Cell Blue:Red Ratios\n",
      "     Cell Number  Red Intensity Sum  Blue Intensity Sum  Blue:Red Ratio  \\\n",
      "0              0            1266085             2256172        1.782007   \n",
      "1              1            1149666             2275660        1.979410   \n",
      "2              2            1159901             2318004        1.998450   \n",
      "3              3            1045283             2147649        2.054610   \n",
      "4              4            1288768             2239595        1.737780   \n",
      "..           ...                ...                 ...             ...   \n",
      "154          154             381420              863410        2.263673   \n",
      "155          155             198928              390146        1.961242   \n",
      "156          156             250727              429060        1.711264   \n",
      "157          157             267545              465518        1.739962   \n",
      "158          158            1099162             2249392        2.046461   \n",
      "\n",
      "     Proportion Infected  \n",
      "0               0.640547  \n",
      "1               0.664363  \n",
      "2               0.666494  \n",
      "3               0.672626  \n",
      "4               0.634741  \n",
      "..                   ...  \n",
      "154             0.693597  \n",
      "155             0.662304  \n",
      "156             0.631168  \n",
      "157             0.635031  \n",
      "158             0.671750  \n",
      "\n",
      "[159 rows x 5 columns]\n",
      "\n",
      "Total Cells: 159\n",
      "Overall Blue:Red Ratio in Image: 1.55\n",
      "Saved results to ../figures/Combined_classification/subset/data/EasyEarly_AS_A_U_22_5_20240717.csv\n",
      "Saved labeled image to ../figures/Combined_classification/subset/classified/EasyEarly_AS_A_U_22_5_20240717_labeled.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# no new function, just call all things and run HLT in-line\n",
    "    # loop through testing images\n",
    "    # call threshold_image()\n",
    "    # call cluster_foreground()\n",
    "    # call make_custom_grayscale()\n",
    "    # call cv2.HoughLinesP()\n",
    "    # reset color channels from image_rgb (threshold_image() output)\n",
    "    # draw lines on image\n",
    "    # setup classification paradigm\n",
    "    # calculate ratios\n",
    "    # write jpgs & csvs\n",
    "\n",
    "# Define vars\n",
    "x_size,y_size=160,120\n",
    "original_x_size,original_y_size=1388,1040 #initial size of input images\n",
    "\n",
    "# Process all images in a folder\n",
    "\n",
    "image_folder = \"../data/images/\" # GitHub WD\n",
    "# image_folder = \"../data/test_images/\" # GitHub WD\n",
    "csv_folder = \"../figures/Combined_classification/data/\" # GitHub WD\n",
    "csv_folder = \"../figures/Combined_classification/classified/\" # GitHub WD\n",
    "    # smaller testing set\n",
    "# image_folder = \"../images/\" # local WD\n",
    "    # larger testing set\n",
    "# image_folder = \"../images/raw/\" # local WD\n",
    "# csv_folder = \"../figures/Combined_classification/subset/data/\"\n",
    "# jpg_folder = \"../figures/Combined_classification/subset/classified\" # local WD\n",
    "\n",
    "image_paths = glob.glob(os.path.join(image_folder, \"*.jpg\"))\n",
    "\n",
    "# WARNING: running this saves a lot of csv and jpg files locally\n",
    "    # loop through testing images\n",
    "for image_path in image_paths:\n",
    "    print(\"\")\n",
    "    print(f\"Processing {os.path.basename(image_path)}\")\n",
    "    # call threshold_image()\n",
    "    image_rgb, thresholded_image, thresh_combined_mask = threshold_image(image_path)\n",
    "    # reset color channels from image_rgb (threshold_image() output)\n",
    "    red_channel,blue_channel=image_rgb[:, :, 0],image_rgb[:, :, 2]\n",
    "    # remove conglomerate pixels (positive results!!)\n",
    "    red_channel=remove_large_background(red_channel,50,10,250)\n",
    "    blue_channel=remove_large_background(blue_channel,50,10,250)\n",
    "    # call cluster_foreground()\n",
    "    foreground_final = cluster_foreground(thresholded_image, thresh_combined_mask)\n",
    "    # set thresholded color channels\n",
    "    fore_red_channel,fore_blue_channel=foreground_final[:, :, 0],foreground_final[:, :, 2]\n",
    "    # call make_custom_grayscale()\n",
    "        # CHANGED: return foreground_mask..?\n",
    "    custom_gray, img = make_custom_grayscale(foreground_final)\n",
    "    # call cv2.HoughLinesP()    \n",
    "    lines = list([list(val[0]) for val in cv2.HoughLinesP(\n",
    "            cv2.resize(custom_gray,(x_size,y_size)), # Input edge image\n",
    "            1, # Distance resolution in pixels\n",
    "            np.pi/180, # Angle resolution in radians\n",
    "            # TRY MAKING THRESHOLD VOTES LOWER (OG was 22)-[10 was too many fp]\n",
    "            threshold=20, # Min number of votes for valid line - lower values will give higher detection rate but also result in more-double counting\n",
    "            # MAKE LEN LOWER (OG WAS 20)\n",
    "            minLineLength=20, # Min allowed length of line - in practice I haven't found changing this parameter either way to help much\n",
    "            maxLineGap=5 # Max allowed gap between line for joining them - lower values with result in better detection rate of spotty cells, but also higher probability that background noise will be misclassified as a cell\n",
    "            )])\n",
    "    \n",
    "    # remove lines with similar slopes\n",
    "    # lines=remove_overlapping_lines(lines)\n",
    "    \n",
    "    # make list of all coordinates\n",
    "    all_coordinates=[]\n",
    "    # original_y_size, original_x_size before in place of numbers, in this order...\n",
    "    img=np.zeros((1388,1040),np.uint8)\n",
    "    print(f\"I counted {len(lines)} cells.\")\n",
    "    print(\"Infection proportions are being calculated...\")\n",
    "    # Define df for csv export\n",
    "    cell_ratios = []\n",
    "    total_cells = len(lines)\n",
    "    # may not need this bc adding it to cell_ratio below\n",
    "    # proportion_infected=[]\n",
    "    annotated_image=np.copy(image_rgb)\n",
    "\n",
    "    #iterate through lines, calculate infection proportion of each cell and annotate the original image with a line and cell number\n",
    "    for cell_number,line in enumerate(lines):\n",
    "        temp_red=fore_red_channel.copy()\n",
    "        temp_blue=fore_blue_channel.copy()\n",
    "\n",
    "        #convert coordinates to size of initial image, pre-downsizing\n",
    "        x1,y1,x2,y2=int(line[0]*original_y_size/y_size),int(line[1]*original_x_size/x_size),int(line[2]*original_y_size/y_size),int(line[3]*original_x_size/x_size)\n",
    "        img=np.zeros((original_y_size, original_x_size),np.uint8)\n",
    "        cv2.line(img,(x1,y1),(x2,y2),255,20)\n",
    "        coords = np.argwhere(img) #returns coordinates of all non-zero pixels i.e. where the line/cell is\n",
    "        all_coordinates.append([f\"{val[0]}_{val[1]}\" for val in coords])\n",
    "\n",
    "        #get an array with pixels filled just at the location of the line, in order to calculate infection proportion\n",
    "        #Q: this uses the binary (0/255) pixel values- would the original continuous values be more meaningful?\n",
    "        subsetted_rgb=image_rgb.copy()\n",
    "        # temp_red=red_channel.copy()\n",
    "        # temp_blue=blue_channel.copy()\n",
    "        target_coordinates={val:\"\" for val in all_coordinates[cell_number]}\n",
    "        for i,row in enumerate(temp_red):\n",
    "                for j,val in enumerate(row):\n",
    "                    # set all non-red pixels to 0\n",
    "                    if f\"{i}_{j}\" not in target_coordinates.keys():\n",
    "                        temp_red[i][j]=0\n",
    "                        temp_blue[i][j]=0\n",
    "                        subsetted_rgb[i][j][0]=0\n",
    "                        subsetted_rgb[i][j][1]=0\n",
    "                        subsetted_rgb[i][j][2]=0\n",
    "        # Calculate blue:red ratio for this cell\n",
    "        red_sum = np.sum(temp_red)\n",
    "        blue_sum = np.sum(temp_blue)\n",
    "        blue_red_ratio = blue_sum / red_sum if red_sum > 0 else 0  # Avoid division by zero\n",
    "        proportion_infected = blue_sum / (blue_sum + red_sum) if (blue_sum + red_sum) > 0 else 0\n",
    "        # add to df for csv export\n",
    "        cell_ratios.append({\n",
    "            'Cell Number': cell_number,\n",
    "            'Red Intensity Sum': red_sum,\n",
    "            'Blue Intensity Sum': blue_sum,\n",
    "            'Blue:Red Ratio': blue_red_ratio,\n",
    "            'Proportion Infected': proportion_infected\n",
    "        })        \n",
    "        # proportion_infected.append(np.sum(temp_blue)/(np.sum(temp_red)+np.sum(temp_blue)))\n",
    "        is_infected=False if proportion_infected<0.2 else True\n",
    "        # is_infected=False if cell_ratios[4][-1] <0.2 else True\n",
    "        # is_infected=False if cell_ratios.at['Proportion Infected', -1] <0.2 else True\n",
    "        # is_infected=False if proportion_infected[-1]<0.2 else True\n",
    "        # Annotate image\n",
    "            # draw lines on image\n",
    "        cv2.line(annotated_image,(x1,y1),(x2,y2),(255,255,255),20) #white line\n",
    "        if is_infected:\n",
    "            number_color=(150, 150, 255)\n",
    "        else:\n",
    "            number_color=(255,150,150)\n",
    "        cv2.putText(\n",
    "            annotated_image, \n",
    "            str(cell_number),  # Label with cell number\n",
    "            (x1,y1),  \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            2,  # Font size\n",
    "            number_color,  # White text\n",
    "            4  # Thickness\n",
    "        )\n",
    "    # print(cell_ratios)\n",
    "    # print(f\"I counted {len([val for val in proportion_infected if val>=0.2])} infected and {len([val for val in proportion_infected if val<0.2])} uninfected cells.\")\n",
    "    print(\"Image processing complete.\")\n",
    "\n",
    "    # 8. Convert ratios to DataFrame for easy viewing\n",
    "    cell_ratios_df = pd.DataFrame(cell_ratios)\n",
    "        # Calculate & report image overall blue:red ratio\n",
    "            # CHANGED from foreground_mask to thresh_combined_mask\n",
    "    total_red = np.sum(red_channel[thresh_combined_mask])\n",
    "            # CHANGED from foreground_mask to thresh_combined_mask\n",
    "    total_blue = np.sum(blue_channel[thresh_combined_mask])\n",
    "    overall_blue_red_ratio = total_blue / total_red if total_red > 0 else 0\n",
    "        # Display results\n",
    "    print(\"\\nIndividual Cell Blue:Red Ratios\")\n",
    "    print(cell_ratios_df)\n",
    "    print(f\"\\nTotal Cells: {total_cells}\")\n",
    "    print(f\"Overall Blue:Red Ratio in Image: {overall_blue_red_ratio:.2f}\")\n",
    "    \n",
    "    # Generate basename\n",
    "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    # Generate .csv output filename based on the input image name\n",
    "    csv_output_path = os.path.join(csv_folder, f\"{base_filename}.csv\")\n",
    "    image_output_path = os.path.join(jpg_folder, f\"{base_filename}_labeled.jpg\")\n",
    "    \n",
    "    # Save the dataframe to a CSV file\n",
    "    cell_ratios_df.to_csv(csv_output_path, index=False)\n",
    "    # Save the image to a JPG file\n",
    "    print(f\"Saved results to {csv_output_path}\")\n",
    "    # Save the labeled image to a JPG file\n",
    "    cv2.imwrite(image_output_path, cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))  # Convert back to BGR for saving\n",
    "    print(f\"Saved labeled image to {image_output_path}\")\n",
    "    cell_ratios_df['Blue:Red Ratio'].hist()\n",
    "\n",
    "    #uncomment below to get inline images\n",
    "    '''\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(13, 10))\n",
    "    ax[0].imshow(image_rgb, cmap='magma')\n",
    "    ax[1].imshow(custom_gray, cmap='magma')\n",
    "    ax[2].imshow(thresholded_image, cmap='magma')\n",
    "    ax[3].imshow(annotated_image, cmap='magma')\n",
    "        # set the title to all subplots\n",
    "    ax[0].set_title(\"Original Image\")\n",
    "    ax[1].set_title(\"Custom Grayscale Image\")\n",
    "    ax[2].set_title(\"Thresholded Image\")\n",
    "    ax[3].set_title(\"Annotated Image\")\n",
    "    # ax[3].set_title(f\"{len([val for val in proportion_infected if val>=infection_threshold])} infected, {len([val for val in proportion_infected if val<infection_threshold])} uninfected\")\n",
    "    fig.tight_layout()\n",
    "    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b35aed-1619-41b8-a3a9-db99fd13b6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e05d3c-5d3a-4efd-aee2-045b4ba83c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check blue\"red ratios for infection populations\n",
    "# cell_ratios_df['Blue:Red Ratio'].hist()\n",
    "# real dataset\n",
    "# /Users/kjehickman/Documents/Research/parasites/E3/data/micrographs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
